{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "10Vd70UYQRFZ66nLUF5lOWRGaUZ4VEY6T",
      "authorship_tag": "ABX9TyN7+NdFkOJuqz3P1H83mn5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nethminikavindya/Nethminikavindya/blob/main/Dataminers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnsUhEUlHNRx",
        "outputId": "d4161865-2bb3-4c62-dc0f-d84e3ca7ced4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QKBWBLf-5zCd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yko7DKGcEL8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/CorrectDataSheet.csv')"
      ],
      "metadata": {
        "id": "WvBX3ND16B02"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPyT9rY6FLHJ",
        "outputId": "1d2503c7-1aee-4c54-88e7-7c98cceaf203"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id                                              title  \\\n",
            "0  i7twOeeg2s8                           cocoÂú®Ê±ÇÊïëÔºü #Â∞è‰∏ë #Â§©‰Ωø #shorts   \n",
            "1  dZKQItATiUY  ‡∂Ø‡∑í‡∂ª‡∑í‡∂∫ ‡∂Ø‡∑ê‡∂ª‡∑í‡∑Ä‡∑ì | Diriya Darivi- Ratta ft @Dimi3 ...   \n",
            "2  s4XMtrbE7LA  Don't miss the end üò± Adi paavi ü§£ #shorts #tren...   \n",
            "3  dO58auXzcR0  ‡∑Ñ‡∑í‡∂ß‡∂¥‡∑î ‡∂¥‡∑ô‡∂∏‡∑ä‡∑Ä‡∂≠‡∑è ‡∂¥‡∂ß‡∑ä‡∂ß ‡∑Ñ‡∑ú‡∂ª‡∑ô‡∂ö‡∑ä... ‡∂Ö‡∂±‡∑ñ - ‡∂ö‡∂±‡∑ñ ‡∂∏‡∑è‡∂∞‡∑ä‚Äç‡∂∫‡∂∫...   \n",
            "4  qpj8XxCEl_A  Creative Justice at the Checkout: Bananas and ...   \n",
            "\n",
            "            publishedAt                 channelId            channelTitle  \\\n",
            "0  2024-11-24T07:30:20Z  UCovvTRDnB3XraOrB9jiSB3A                    Â•Ω‰∫∫Â∞è‰∏ë   \n",
            "1  2024-11-30T03:30:20Z  UCJbxRq_IlWyzvB9KK0Mrs8A                   Ratta   \n",
            "2  2024-11-23T14:40:01Z  UCaXy6RW7Thxx99_p0y3TpWA  ChandruPriya love life   \n",
            "3  2024-11-30T11:02:10Z  UCYAQZcyFBNCV29y-7jgoYfQ             Hiru Gossip   \n",
            "4  2024-11-24T14:00:52Z  UCF5Rp2ghzXsX6vwYqa7aepg  Fabiosa Best Lifehacks   \n",
            "\n",
            "   categoryId trending_date  \\\n",
            "0          22      24.01.12   \n",
            "1          23      24.01.12   \n",
            "2          24      24.01.12   \n",
            "3          24      24.01.12   \n",
            "4          22      24.01.12   \n",
            "\n",
            "                                                tags  view_count    likes  \\\n",
            "0  Â•Ω‰∫∫Â∞è‰∏ë|ÁæéÂõΩÈòüÈïø|ËßíËâ≤ÊâÆÊºî|‰∫åÊ¨°ÂÖÉ|ÁæéÊº´|Ëø∑‰∫∫ÂùèËõã|Ë∂ÖÁ∫ßËã±ÈõÑ|ÊêûÁ¨ëËßÜÈ¢ë|Ê≠£ËÉΩÈáè|Êº´ÁîªÁà±Â•ΩËÄÖ...    70750024  1437972   \n",
            "1  ratta|ratta new|retta|comedy|pathola|patola|re...      503804    37131   \n",
            "2  shorts|trending|viral|lovely|love Marriage|bes...    34775106   408820   \n",
            "3  Hiru gossip|gossip|lanka gossip|sri lanka|goss...      197895     4679   \n",
            "4  karma|memes|funny|shorts|tik tok|tiktok|funny ...    30924326   589314   \n",
            "\n",
            "   dislike  comment_count duration  \\\n",
            "0        0           1583    PT29S   \n",
            "1        0           1739  PT14M8S   \n",
            "2        0            210    PT22S   \n",
            "3        0           2290  PT27M8S   \n",
            "4        0           6552    PT18S   \n",
            "\n",
            "                                   thumbnail_link  comments_disabled  \\\n",
            "0  https://i.ytimg.com/vi/i7twOeeg2s8/default.jpg              False   \n",
            "1  https://i.ytimg.com/vi/dZKQItATiUY/default.jpg              False   \n",
            "2  https://i.ytimg.com/vi/s4XMtrbE7LA/default.jpg              False   \n",
            "3  https://i.ytimg.com/vi/dO58auXzcR0/default.jpg              False   \n",
            "4  https://i.ytimg.com/vi/qpj8XxCEl_A/default.jpg              False   \n",
            "\n",
            "  ratings_disabled                                        description  \n",
            "0            FALSE  Ê¨¢ËøéÊù•Âà∞„ÄêÂ•Ω‰∫∫Â∞è‰∏ë„ÄëÈ¢ëÈÅìÔºåËøôÈáåÊòØÂ•Ω‰∫∫Â∞è‰∏ëÁöÑËßíËâ≤ÊâÆÊºî„ÄÅ‰∫åÊ¨°ÂÖÉÁæéÊº´ÁöÑÈõÜÁªìÂú∞ÔºåÂêåÊó∂‰πüÊòØÊàëËøô‰∏™Ëá™Áß∞‚Äú...  \n",
            "1            FALSE  ‡∂Ø‡∑î‡∂¥‡∑ä‡∂¥‡∂≠‡∑ä ‡∂Ö‡∑É‡∂ª‡∂´ ‡∂Ø‡∑í‡∂ª‡∑í‡∂∫ ‡∂Ø‡∑ê‡∂ª‡∑í‡∑Ä‡∑í‡∂∫‡∂ö‡∂ß ‡∂ã‡∂Ø‡∑Ä‡∑î ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ú‡∑í‡∑Ñ‡∑í‡∂Ç ...  \n",
            "2            FALSE  Don't miss the end üò± Adi paavi ü§£ #shorts #tren...  \n",
            "3            FALSE  ‡∑Ñ‡∑í‡∂ß‡∂¥‡∑î ‡∂¥‡∑ô‡∂∏‡∑ä‡∑Ä‡∂≠‡∑è ‡∂¥‡∂ß‡∑ä‡∂ß ‡∑Ñ‡∑ú‡∂ª‡∑ô‡∂ö‡∑ä... ‡∂Ö‡∂±‡∑ñ - ‡∂ö‡∂±‡∑ñ ‡∂∏‡∑è‡∂∞‡∑ä‚Äç‡∂∫‡∂∫...  \n",
            "4            FALSE  When a customer decided to peel her bananas be...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2IrckfYFOk1",
        "outputId": "52650ea6-9169-4d75-8549-ce5c37e6a1c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video_id               0\n",
            "title                  0\n",
            "publishedAt            0\n",
            "channelId              0\n",
            "channelTitle           0\n",
            "categoryId             0\n",
            "trending_date          0\n",
            "tags                   0\n",
            "view_count             0\n",
            "likes                  0\n",
            "dislike                0\n",
            "comment_count          0\n",
            "duration             225\n",
            "thumbnail_link         0\n",
            "comments_disabled      0\n",
            "ratings_disabled      11\n",
            "description          487\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCVUbQvVOPNW",
        "outputId": "14ede7e5-0723-4b0f-b7cc-88b989497866"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['video_id', 'title', 'publishedAt', 'channelId', 'channelTitle',\n",
            "       'categoryId', 'trending_date', 'tags', 'view_count', 'likes', 'dislike',\n",
            "       'comment_count', 'duration', 'thumbnail_link', 'comments_disabled',\n",
            "       'ratings_disabled', 'description'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0F6NA_MxFV75"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text data\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    return text"
      ],
      "metadata": {
        "id": "RvxjI7-mGCrc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df[['title', 'description', 'tags']].isnull().sum())\n",
        "\n",
        "# Check data types\n",
        "print(df[['title', 'description', 'tags']].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3khU4tsC6UaL",
        "outputId": "bce39268-bd05-4d75-b7dc-3fddb348682c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title            0\n",
            "description    487\n",
            "tags             0\n",
            "dtype: int64\n",
            "title          object\n",
            "description    object\n",
            "tags           object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with empty strings and convert to string type\n",
        "df['title'] = df['title'].fillna('').astype(str)\n",
        "df['description'] = df['description'].fillna('').astype(str)\n",
        "df['tags'] = df['tags'].fillna('').astype(str)"
      ],
      "metadata": {
        "id": "Rkvb1OMu6Z_-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text in each column\n",
        "df['cleaned_title'] = df['title'].apply(clean_text)\n",
        "df['cleaned_description'] = df['description'].apply(clean_text)\n",
        "df['cleaned_tags'] = df['tags'].apply(clean_text)\n",
        "\n",
        "# Display the DataFrame with the new cleaned columns\n",
        "print(df[['title', 'cleaned_title', 'description', 'cleaned_description', 'tags', 'cleaned_tags']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iddOd2avGFmY",
        "outputId": "87961a5d-76f8-460b-c4e8-d97c22bfe2c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0                           cocoÂú®Ê±ÇÊïëÔºü #Â∞è‰∏ë #Â§©‰Ωø #shorts   \n",
            "1  ‡∂Ø‡∑í‡∂ª‡∑í‡∂∫ ‡∂Ø‡∑ê‡∂ª‡∑í‡∑Ä‡∑ì | Diriya Darivi- Ratta ft @Dimi3 ...   \n",
            "2  Don't miss the end üò± Adi paavi ü§£ #shorts #tren...   \n",
            "3  ‡∑Ñ‡∑í‡∂ß‡∂¥‡∑î ‡∂¥‡∑ô‡∂∏‡∑ä‡∑Ä‡∂≠‡∑è ‡∂¥‡∂ß‡∑ä‡∂ß ‡∑Ñ‡∑ú‡∂ª‡∑ô‡∂ö‡∑ä... ‡∂Ö‡∂±‡∑ñ - ‡∂ö‡∂±‡∑ñ ‡∂∏‡∑è‡∂∞‡∑ä‚Äç‡∂∫‡∂∫...   \n",
            "4  Creative Justice at the Checkout: Bananas and ...   \n",
            "\n",
            "                                       cleaned_title  \\\n",
            "0                                      coco   shorts   \n",
            "1        diriya darivi ratta ft dimi ratta new video   \n",
            "2  dont miss the end  adi paavi  shorts trending ...   \n",
            "3                                                      \n",
            "4  creative justice at the checkout bananas and e...   \n",
            "\n",
            "                                         description  \\\n",
            "0  Ê¨¢ËøéÊù•Âà∞„ÄêÂ•Ω‰∫∫Â∞è‰∏ë„ÄëÈ¢ëÈÅìÔºåËøôÈáåÊòØÂ•Ω‰∫∫Â∞è‰∏ëÁöÑËßíËâ≤ÊâÆÊºî„ÄÅ‰∫åÊ¨°ÂÖÉÁæéÊº´ÁöÑÈõÜÁªìÂú∞ÔºåÂêåÊó∂‰πüÊòØÊàëËøô‰∏™Ëá™Áß∞‚Äú...   \n",
            "1  ‡∂Ø‡∑î‡∂¥‡∑ä‡∂¥‡∂≠‡∑ä ‡∂Ö‡∑É‡∂ª‡∂´ ‡∂Ø‡∑í‡∂ª‡∑í‡∂∫ ‡∂Ø‡∑ê‡∂ª‡∑í‡∑Ä‡∑í‡∂∫‡∂ö‡∂ß ‡∂ã‡∂Ø‡∑Ä‡∑î ‡∂ö‡∂ª‡∂±‡∑ä‡∂± ‡∂ú‡∑í‡∑Ñ‡∑í‡∂Ç ...   \n",
            "2  Don't miss the end üò± Adi paavi ü§£ #shorts #tren...   \n",
            "3  ‡∑Ñ‡∑í‡∂ß‡∂¥‡∑î ‡∂¥‡∑ô‡∂∏‡∑ä‡∑Ä‡∂≠‡∑è ‡∂¥‡∂ß‡∑ä‡∂ß ‡∑Ñ‡∑ú‡∂ª‡∑ô‡∂ö‡∑ä... ‡∂Ö‡∂±‡∑ñ - ‡∂ö‡∂±‡∑ñ ‡∂∏‡∑è‡∂∞‡∑ä‚Äç‡∂∫‡∂∫...   \n",
            "4  When a customer decided to peel her bananas be...   \n",
            "\n",
            "                                 cleaned_description  \\\n",
            "0                                                      \n",
            "1                       diriya darivi       dimi ...   \n",
            "2  dont miss the end  adi paavi  shorts trending ...   \n",
            "3                                                ...   \n",
            "4  when a customer decided to peel her bananas be...   \n",
            "\n",
            "                                                tags  \\\n",
            "0  Â•Ω‰∫∫Â∞è‰∏ë|ÁæéÂõΩÈòüÈïø|ËßíËâ≤ÊâÆÊºî|‰∫åÊ¨°ÂÖÉ|ÁæéÊº´|Ëø∑‰∫∫ÂùèËõã|Ë∂ÖÁ∫ßËã±ÈõÑ|ÊêûÁ¨ëËßÜÈ¢ë|Ê≠£ËÉΩÈáè|Êº´ÁîªÁà±Â•ΩËÄÖ...   \n",
            "1  ratta|ratta new|retta|comedy|pathola|patola|re...   \n",
            "2  shorts|trending|viral|lovely|love Marriage|bes...   \n",
            "3  Hiru gossip|gossip|lanka gossip|sri lanka|goss...   \n",
            "4  karma|memes|funny|shorts|tik tok|tiktok|funny ...   \n",
            "\n",
            "                                        cleaned_tags  \n",
            "0                                                     \n",
            "1  rattaratta newrettacomedypatholapatolaretta vi...  \n",
            "2  shortstrendingvirallovelylove marriagebest com...  \n",
            "3  hiru gossipgossiplanka gossipsri lankagossip l...  \n",
            "4  karmamemesfunnyshortstik toktiktokfunny videom...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the cleaned text columns into a single column\n",
        "df['combined_text'] = df['cleaned_title'] + ' ' + df['cleaned_description'] + ' ' + df['cleaned_tags']\n",
        "\n",
        "# Display the combined text column\n",
        "print(df[['combined_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDWpqKDAGIRj",
        "outputId": "c83c57af-2d4f-4da9-fa0f-2371dfca5546"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       combined_text\n",
            "0                                  coco   shorts    \n",
            "1     diriya darivi ratta ft dimi ratta new video...\n",
            "2  dont miss the end  adi paavi  shorts trending ...\n",
            "3                                                ...\n",
            "4  creative justice at the checkout bananas and e...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert text to numerical features using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features\n",
        "X = vectorizer.fit_transform(df['combined_text']).toarray()\n",
        "\n",
        "# Display the shape of the feature matrix\n",
        "print(\"Shape of X:\", X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdDcgKvC7M1d",
        "outputId": "cafbf9b6-2408-4203-9222-54b0430d4fa8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1350, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Define a function to get sentiment polarity\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'positive'\n",
        "    elif analysis.sentiment.polarity == 0:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'negative'\n",
        "\n",
        "# Apply the function to generate sentiment labels\n",
        "df['sentiment'] = df['combined_text'].apply(get_sentiment)\n",
        "\n",
        "# Display the DataFrame with the new sentiment column\n",
        "print(df[['combined_text', 'sentiment']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgCYpM8o-8Tp",
        "outputId": "9c08a500-28ca-4e0f-ec44-d8b1d25f35a4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       combined_text sentiment\n",
            "0                                  coco   shorts       neutral\n",
            "1     diriya darivi ratta ft dimi ratta new video...  positive\n",
            "2  dont miss the end  adi paavi  shorts trending ...  positive\n",
            "3                                                ...  positive\n",
            "4  creative justice at the checkout bananas and e...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target variable\n",
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "Od7dO-KO_Qhs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Wh64XOTNANuO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shapes of the training and testing sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls3biTJkAP2D",
        "outputId": "9a9dcf2e-d2d1-4859-c309-e4b37bf90fc7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (1080, 5000)\n",
            "Shape of X_test: (270, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "a1F3nYwNAxJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize and train the model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_reg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiFNrLmxAcjv",
        "outputId": "4e2b9d92-ac36-4510-fc06-ee0632be3806"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "Accuracy: 0.9444444444444444\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.44      0.61        16\n",
            "     neutral       0.92      0.96      0.94        80\n",
            "    positive       0.96      0.98      0.97       174\n",
            "\n",
            "    accuracy                           0.94       270\n",
            "   macro avg       0.96      0.79      0.84       270\n",
            "weighted avg       0.95      0.94      0.94       270\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  7   4   5]\n",
            " [  0  77   3]\n",
            " [  0   3 171]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "7f9F1855A7rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize and train the model\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeR3wlPCAft_",
        "outputId": "a48a1411-751a-47a2-e1c9-f539e69ea3d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Results:\n",
            "Accuracy: 0.9851851851851852\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00        16\n",
            "     neutral       0.99      0.96      0.97        80\n",
            "    positive       0.98      0.99      0.99       174\n",
            "\n",
            "    accuracy                           0.99       270\n",
            "   macro avg       0.99      0.99      0.99       270\n",
            "weighted avg       0.99      0.99      0.99       270\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 16   0   0]\n",
            " [  0  77   3]\n",
            " [  0   1 173]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "TSGpGqU3BPJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Initialize and train the model\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Naive Bayes Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iK--mrEBVub",
        "outputId": "52032f82-6366-44db-974f-6bf89cef1f59"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "Accuracy: 0.9111111111111111\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.31      0.48        16\n",
            "     neutral       0.89      0.94      0.91        80\n",
            "    positive       0.92      0.95      0.94       174\n",
            "\n",
            "    accuracy                           0.91       270\n",
            "   macro avg       0.94      0.73      0.78       270\n",
            "weighted avg       0.91      0.91      0.90       270\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  5   1  10]\n",
            " [  0  75   5]\n",
            " [  0   8 166]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "42iysKa0BcCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and train the model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKPCEHrABfSJ",
        "outputId": "1fa8911d-4855-4f73-d264-159f883f722a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Results:\n",
            "Accuracy: 0.9851851851851852\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00        16\n",
            "     neutral       0.96      0.99      0.98        80\n",
            "    positive       0.99      0.98      0.99       174\n",
            "\n",
            "    accuracy                           0.99       270\n",
            "   macro avg       0.99      0.99      0.99       270\n",
            "weighted avg       0.99      0.99      0.99       270\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 16   0   0]\n",
            " [  0  79   1]\n",
            " [  0   3 171]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare Model Performance**"
      ],
      "metadata": {
        "id": "1tOHFtPrBoGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaMNCJgyBg-S",
        "outputId": "1ee59073-4d3e-4859-c8c9-18a5a3397155"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9444444444444444\n",
            "SVM Accuracy: 0.9851851851851852\n",
            "Naive Bayes Accuracy: 0.9111111111111111\n",
            "Random Forest Accuracy: 0.9851851851851852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IKZyjyjVBkKU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}